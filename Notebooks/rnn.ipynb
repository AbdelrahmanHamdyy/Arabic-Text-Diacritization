{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Char [['m', 's', '>', 'l', 'p'], ['w', 'm', 'n'], ['H', 'n', 'v'], ['w', 'h', 'w'], ['q', 'A', 'd', 'r'], ['E', 'l', 'Y'], ['A', 'l', '<', 'T', 'E', 'A', 'm'], ['>', 'w'], ['A', 'l', 'k', 's', 'w', 'p'], ['>', 'w'], ['A', 'l', 'E', 't', 'q'], ['v', 'm'], ['A', 'f', 't', 'q', 'r'], ['f', 'E', 'j', 'z'], ['E', 'n'], ['k', 'l'], ['*', 'l', 'k'], ['l', 'm'], ['y', 'j', 'z', 'h'], ['A', 'l', 'S', 'w', 'm'], ['>', 'S', 'l', 'A']]\n",
      "Diac [['a', 'o', 'a', 'a', 'N'], ['a', 'a', 'o'], ['a', 'i', 'a'], ['a', 'u', 'a'], ['a', ' ', 'i', 'N'], ['a', 'a', ' '], [' ', ' ', 'i', 'o', 'a', ' ', 'i'], ['a', 'o'], [' ', 'o', 'i', 'o', 'a', 'i'], ['a', 'o'], [' ', 'o', 'i', 'o', 'i'], ['u', '~a'], [' ', 'o', 'a', 'a', 'a'], ['a', 'a', 'a', 'a'], ['a', 'o'], ['u', '~i'], ['a', 'i', 'a'], ['a', 'o'], ['u', 'o', 'i', 'i'], [' ', ' ', '~a', 'o', 'u'], ['a', 'o', 'F', ' ']]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "%run preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get unique characters and diacritics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "unique_characters = ['A', 'b', 't', 'v', 'j', 'H', 'x', 'd', '*', 'r', 'z', 's', '$', 'S', 'D', 'T', 'Z', 'E', 'g', 'f', 'q', 'k', 'l', 'm', 'n', 'h', 'w', 'y', \"'\", '>', '<', '&', '}', '|', '{', '`', 'Y', 'p']\n",
    "unique_diacritics = ['o', 'a', 'i', '~', 'u', 'N', 'F', 'K', ' ', '~a', '~i', '~u', '~N', '~F', '~K']\n",
    "\n",
    "num_chars = len(unique_characters)\n",
    "num_classes = len(unique_diacritics)\n",
    "\n",
    "char_to_index = {char: i for i, char in enumerate(unique_characters)}\n",
    "diacritic_to_index = {diacritic: i for i, diacritic in enumerate(unique_diacritics)}\n",
    "\n",
    "print(num_chars)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2102068, 13)\n",
      "(2102068, 13)\n"
     ]
    }
   ],
   "source": [
    "def readFile(path):\n",
    "\tsentences = []\n",
    "\twith open(path, 'r', encoding='utf-8') as file:\n",
    "\t\tfor line in file:\n",
    "\t\t\tsentences.append(line.strip())\n",
    "\n",
    "\treturn sentences\n",
    "\n",
    "PATH = \"../dataset/train.txt\"\n",
    "corpus = readFile(PATH)\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "max_sequence_length = 0\n",
    "\n",
    "# Clean each sentence in the corpus\n",
    "for sentence in corpus:\n",
    "\tclean_sentence = run_buckwalter(sentence)\n",
    "\tchar_list, diacritics_list = extract_labels(clean_sentence)\n",
    "\n",
    "\tX_train.append(char_list)\n",
    "\ty_train.append(diacritics_list)\n",
    "\n",
    "\tmax_sequence_length = max(max_sequence_length, max(len(word) for word in char_list))\n",
    "\n",
    "\n",
    "# Encoding and Padding\n",
    "X_train_padded = []\n",
    "for sentence in X_train:\n",
    "\tX_train_sequences = [[char_to_index[char] for char in word] for word in sentence]\n",
    "\tX_train_padded.append(pad_sequences(X_train_sequences, maxlen=max_sequence_length, padding='post'))\n",
    "\n",
    "X_train_padded = np.concatenate(X_train_padded, axis=0)\n",
    "print(X_train_padded.shape)\n",
    "\n",
    "y_train_padded = []\n",
    "for sentence in y_train:\n",
    "\ty_train_sequences = [[diacritic_to_index[diacritic] for diacritic in diacritic_sequence] for diacritic_sequence in sentence]\n",
    "\ty_train_padded.append(pad_sequences(y_train_sequences, maxlen=max_sequence_length, padding='post'))\n",
    "\n",
    "y_train_padded = np.concatenate(y_train_padded, axis=0)\n",
    "print(y_train_padded.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "65690/65690 [==============================] - 427s 6ms/step - loss: 0.2311 - accuracy: 0.9128\n",
      "Epoch 2/3\n",
      "65690/65690 [==============================] - 426s 6ms/step - loss: 0.2101 - accuracy: 0.9194\n",
      "Epoch 3/3\n",
      "65690/65690 [==============================] - 419s 6ms/step - loss: 0.2070 - accuracy: 0.9204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b024aa0ad0>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define your model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=num_chars, output_dim=embedding_dim, input_length=max_sequence_length))\n",
    "model.add(LSTM(units=100, return_sequences=True))\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "# Compile your model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train your model\n",
    "model.fit(X_train_padded, y_train_padded, epochs=num_epochs)#, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate your model\n",
    "# accuracy = model.evaluate(X_val, y_val)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "فَأَشَبَهَ مَا لَوْ اسْتَعْمَلَ نَفْسِهِ فَي الْإِجَارَةِ أَيْ وَمَا تَحْصِلَ مَنْ إجَارَتُهُ \n"
     ]
    }
   ],
   "source": [
    "sentence = \"فأشبه ما لو استعمل نفسه في الإجارة أي وما تحصل من إجارته\"\n",
    "clean_sentence = run_buckwalter(sentence)\n",
    "char_list, _ = extract_labels(clean_sentence)\n",
    "\n",
    "X_test_sequences = [[char_to_index[char] for char in word] for word in char_list]\n",
    "X_test = pad_sequences(X_test_sequences, maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "final_output = []\n",
    "index = 0\n",
    "index_to_diacritic = {index: diacritic for diacritic, index in diacritic_to_index.items()}\n",
    "\n",
    "\n",
    "new = sentence.split()\n",
    "index = 0\n",
    "\n",
    "for word in predictions:\n",
    "\tfor i in range(len(new[index])):\n",
    "\t\tfinal_output.append(new[index][i])\n",
    "\t\tmax_index = np.array(word[i]).argmax()\n",
    "\n",
    "\t\tif index_to_diacritic[max_index] != \" \":\n",
    "\t\t\tfinal_output.append(buckwalter.untransliterate(index_to_diacritic[max_index]))\n",
    "\t\n",
    "\tindex += 1\n",
    "\tfinal_output.append(\" \")\n",
    "\n",
    "final_output = \"\".join(final_output)\n",
    "\n",
    "print(final_output)\n",
    "# print(buckwalter.transliterate(\"عَنْ سَالِمِ بْنِ عَبْدِ اللَّهِ\"))\n",
    "# print(buckwalter.transliterate(final_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
