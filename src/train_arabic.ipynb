{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ق', 'و', 'ل', 'ه'], ['ل', 'ع', 'د', 'م'], ['م', 'ا'], ['ت', 'ت', 'ع', 'ل', 'ق'], ['إ', 'ل', 'خ'], ['أ', 'ي'], ['ا', 'ل', 'و', 'ص', 'ي', 'ة'], ['ق', 'و', 'ل', 'ه'], ['م', 'ا'], ['م', 'ر'], ['أ', 'ي'], ['ق', 'ب', 'ي', 'ل'], ['ق', 'و', 'ل'], ['ا', 'ل', 'م', 'ت', 'ن'], ['ل', 'غ', 'ت'], ['و', 'ل', 'و'], ['ا', 'ق', 'ت', 'ص', 'ر'], ['ع', 'ل', 'ى'], ['أ', 'و', 'ص', 'ي', 'ت'], ['ل', 'ه'], ['ب', 'ش', 'ا', 'ة'], ['أ', 'و'], ['أ', 'ع', 'ط', 'و', 'ه'], ['ش', 'ا', 'ة'], ['و', 'ل', 'ا'], ['غ', 'ن', 'م'], ['ل', 'ه'], ['ع', 'ن', 'د'], ['ا', 'ل', 'م', 'و', 'ت'], ['ه', 'ل'], ['ت', 'ب', 'ط', 'ل'], ['ا', 'ل', 'و', 'ص', 'ي', 'ة'], ['أ', 'و'], ['ي', 'ش', 'ت', 'ر', 'ى'], ['ل', 'ه'], ['ش', 'ا', 'ة'], ['و', 'ي', 'ؤ', 'خ', 'ذ'], ['م', 'ن'], ['ق', 'و', 'ل', 'ه'], ['ا', 'ل', 'آ', 'ت', 'ي'], ['ك', 'م', 'ا'], ['ل', 'و'], ['ل', 'م'], ['ي', 'ق', 'ل'], ['م', 'ن'], ['م', 'ا', 'ل', 'ي'], ['و', 'ل', 'ا'], ['م', 'ن'], ['غ', 'ن', 'م', 'ي'], ['أ', 'ن', 'ه', 'ا'], ['ل', 'ا'], ['ت', 'ب', 'ط', 'ل'], ['و', 'ع', 'ب', 'ا', 'ر', 'ة'], ['ا', 'ل', 'ك', 'ن', 'ز'], ['و', 'ل', 'و'], ['ل', 'م'], ['ي', 'ق', 'ل'], ['م', 'ن'], ['م', 'ا', 'ل', 'ي'], ['و', 'ل', 'ا'], ['م', 'ن'], ['غ', 'ن', 'م', 'ي'], ['ل', 'م'], ['ي', 'ت', 'ع', 'ي', 'ن'], ['غ', 'ن', 'م', 'ه'], ['إ', 'ن'], ['ك', 'ا', 'ن', 'ت'], ['ا', 'ن', 'ت', 'ه', 'ت'], [], [], ['س', 'م'], ['ق', 'و', 'ل', 'ه'], ['ف', 'ي', 'ع', 'ط', 'ى'], ['و', 'ا', 'ح', 'د', 'ة'], ['م', 'ن', 'ه', 'ا'], ['إ', 'ل', 'خ'], ['ك', 'م', 'ا'], ['ل', 'و'], ['ك', 'ا', 'ن', 'ت'], ['م', 'و', 'ج', 'و', 'د', 'ة'], ['ع', 'ن', 'د'], ['ا', 'ل', 'و', 'ص', 'ي', 'ة'], ['و', 'ا', 'ل', 'م', 'و', 'ت'], ['و', 'ل', 'ا'], ['ي', 'ج', 'و', 'ز'], ['أ', 'ن'], ['ي', 'ع', 'ط', 'ى'], ['و', 'ا', 'ح', 'د', 'ة'], ['م', 'ن'], ['غ', 'ي', 'ر'], ['غ', 'ن', 'م', 'ه'], ['ف', 'ي'], ['ا', 'ل', 'ص', 'و', 'ر', 'ت', 'ي', 'ن'], ['و', 'إ', 'ن'], ['ت', 'ر', 'ا', 'ض', 'ي', 'ا'], ['ل', 'أ', 'ن', 'ه'], ['ص', 'ل', 'ح'], ['ع', 'ل', 'ى'], ['م', 'ج', 'ه', 'و', 'ل'], ['م', 'غ', 'ن', 'ي'], ['و', 'ن', 'ه', 'ا', 'ي', 'ة'], ['ق', 'ا', 'ل'], [], [], ['ق', 'و', 'ل', 'ه'], ['و', 'ا', 'ح', 'د', 'ة'], ['م', 'ن', 'ه', 'ا'], ['أ', 'ي'], ['ك', 'ا', 'م', 'ل', 'ة'], ['و', 'ل', 'ا'], ['ي', 'ج', 'و', 'ز'], ['أ', 'ن'], ['ي', 'ع', 'ط', 'ى'], ['ن', 'ص', 'ف', 'ي', 'ن'], ['م', 'ن'], ['ش', 'ا', 'ت', 'ي', 'ن'], ['ل', 'أ', 'ن', 'ه'], ['ل', 'ا'], ['ي', 'س', 'م', 'ى'], ['ش', 'ا', 'ة'], ['و', 'ق', 'و', 'ل', 'ه'], ['و', 'ل', 'ا'], ['ي', 'ج', 'و', 'ز'], ['أ', 'ن'], ['ي', 'ع', 'ط', 'ى'], ['و', 'ا', 'ح', 'د', 'ة'], ['م', 'ن'], ['غ', 'ي', 'ر'], ['غ', 'ن', 'م', 'ه'], ['و', 'ي', 'ن', 'ب', 'غ', 'ي'], ['أ', 'ن'], ['ي', 'ق', 'ا', 'ل'], ['م', 'ث', 'ل'], ['ذ', 'ل', 'ك'], ['ف', 'ي'], ['ا', 'ل', 'أ', 'ر', 'ق', 'ا', 'ء'], [], []]\n",
      "[['َ', 'ْ', 'ُ', 'ُ'], ['ِ', 'َ', 'َ', 'ِ'], ['َ', ' '], ['َ', 'َ', 'َ', 'َّ', 'ُ'], [' ', 'َ', 'ْ'], ['َ', 'ْ'], [' ', 'ْ', 'َ', 'ِ', 'َّ', 'ُ'], ['َ', 'ْ', 'ُ', 'ُ'], ['َ', ' '], ['َ', 'َّ'], ['َ', 'ْ'], ['ُ', 'َ', 'ْ', 'َ'], ['َ', 'ْ', 'ِ'], [' ', 'ْ', 'َ', 'ْ', 'ِ'], ['َ', 'َ', 'ْ'], ['َ', 'َ', 'ْ'], [' ', 'ْ', 'َ', 'َ', 'َ'], ['َ', 'َ', ' '], ['َ', 'ْ', 'َ', 'ْ', ' '], ['َ', 'ُ'], ['ِ', 'َ', ' ', 'ٍ'], ['َ', 'ْ'], ['َ', 'ْ', 'ُ', ' ', 'ُ'], ['َ', ' ', 'ً'], ['َ', 'َ', ' '], ['َ', 'َ', 'َ'], ['َ', 'ُ'], ['ِ', 'ْ', 'َ'], [' ', 'ْ', 'َ', 'ْ', 'ِ'], ['َ', 'ْ'], ['َ', 'ْ', 'ُ', 'ُ'], [' ', 'ْ', 'َ', 'ِ', 'َّ', 'ُ'], ['َ', 'ْ'], ['ُ', 'ْ', 'َ', 'َ', ' '], ['َ', 'ُ'], ['َ', ' ', 'ٌ'], ['َ', 'ُ', 'ْ', 'َ', 'ُ'], ['ِ', 'ْ'], ['َ', 'ْ', 'ِ', 'ِ'], [' ', 'ْ', ' ', 'ِ', ' '], ['َ', 'َ', ' '], ['َ', 'ْ'], ['َ', 'ْ'], ['َ', 'ُ', 'ْ'], ['ِ', 'ْ'], ['َ', ' ', 'ِ', ' '], ['َ', 'َ', ' '], ['ِ', 'ْ'], ['َ', 'َ', 'ِ', ' '], ['َ', 'َّ', 'َ', ' '], ['َ', ' '], ['َ', 'ْ', 'ُ', 'ُ'], ['َ', 'ِ', 'َ', ' ', 'َ', 'ُ'], [' ', 'ْ', 'َ', 'ْ', 'ِ'], ['َ', 'َ', 'ْ'], ['َ', 'ْ'], ['َ', 'ُ', 'ْ'], ['ِ', 'ْ'], ['َ', ' ', 'ِ', ' '], ['َ', 'َ', ' '], ['ِ', 'ْ'], ['َ', 'َ', 'ِ', ' '], ['َ', 'ْ'], ['َ', 'َ', 'َ', 'َّ', 'ْ'], ['َ', 'َ', 'ُ', 'ُ'], [' ', 'ْ'], ['َ', ' ', 'َ', 'ْ'], [' ', 'ْ', 'َ', 'َ', 'ْ'], [], [], [' ', ' '], ['َ', 'ْ', 'ُ', 'ُ'], ['َ', 'ُ', 'ْ', 'َ', ' '], ['َ', ' ', 'ِ', 'َ', 'ً'], ['ِ', 'ْ', 'َ', ' '], [' ', 'َ', 'ْ'], ['َ', 'َ', ' '], ['َ', 'ْ'], ['َ', ' ', 'َ', 'ْ'], ['َ', 'ْ', 'ُ', ' ', 'َ', 'ً'], ['ِ', 'ْ', 'َ'], [' ', 'ْ', 'َ', 'ِ', 'َّ', 'ِ'], ['َ', ' ', 'ْ', 'َ', 'ْ', 'ِ'], ['َ', 'َ', ' '], ['َ', 'ُ', ' ', 'ُ'], ['َ', 'ْ'], ['ُ', 'ْ', 'َ', ' '], ['َ', ' ', 'ِ', 'َ', 'ً'], ['ِ', 'ْ'], ['َ', 'ْ', 'ِ'], ['َ', 'َ', 'ِ', 'ِ'], ['ِ', ' '], [' ', ' ', 'ُّ', ' ', 'َ', 'َ', 'ْ', 'ِ'], ['َ', 'ِ', 'ْ'], ['َ', 'َ', ' ', 'َ', 'َ', ' '], ['ِ', 'َ', 'َّ', 'ُ'], ['ُ', 'ْ', 'ٌ'], ['َ', 'َ', ' '], ['َ', 'ْ', 'ُ', ' ', 'ٍ'], ['ُ', 'ْ', 'ِ', ' '], ['َ', 'ِ', 'َ', ' ', 'َ', 'ٌ'], ['َ', ' ', 'َ'], [], [], ['َ', 'ْ', 'ُ', 'ُ'], ['َ', ' ', 'ِ', 'َ', 'ً'], ['ِ', 'ْ', 'َ', ' '], ['َ', 'ْ'], ['َ', ' ', 'ِ', 'َ', 'ً'], ['َ', 'َ', ' '], ['َ', 'ُ', ' ', 'ُ'], ['َ', 'ْ'], ['ُ', 'ْ', 'َ', ' '], ['ِ', 'ْ', 'َ', 'ْ', 'ِ'], ['ِ', 'ْ'], ['َ', ' ', 'َ', 'ْ', 'ِ'], ['ِ', 'َ', 'َّ', 'ُ'], ['َ', ' '], ['ُ', 'َ', 'َّ', ' '], ['َ', ' ', 'ً'], ['َ', 'َ', 'ْ', 'ُ', 'ُ'], ['َ', 'َ', ' '], ['َ', 'ُ', ' ', 'ُ'], ['َ', 'ْ'], ['ُ', 'ْ', 'َ', ' '], ['َ', ' ', 'ِ', 'َ', 'ً'], ['ِ', 'ْ'], ['َ', 'ْ', 'ِ'], ['َ', 'َ', 'ِ', 'ِ'], ['َ', 'َ', 'ْ', 'َ', 'ِ', ' '], ['َ', 'ْ'], ['ُ', 'َ', ' ', 'َ'], ['ِ', 'ْ', 'ُ'], ['َ', 'ِ', 'َ'], ['ِ', ' '], [' ', 'ْ', 'َ', 'ِ', 'َّ', ' ', 'ِ'], [], []]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from TorchCRF import CRF\n",
    "\n",
    "%run updatePreprocessing.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 200\n",
    "HIDDEN_SIZE = 512\n",
    "NUM_LAYERS = 1\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 256\n",
    "VOCAB_SIZE = len(basic_arabic_letters) + 1\n",
    "LABELS_SIZE = len(DIACRITICS)\n",
    "\n",
    "TRAIN_PATH = \"../dataset/train.txt\"\n",
    "VAL_PATH = \"../dataset/val.txt\"\n",
    "LSTM_PATH=\"./models/lstm.pth\"\n",
    "RNN_PATH=\"./models/rnn.pth\"\n",
    "CNN_PATH = \"./models/cnn.pth\"\n",
    "CRF_PATH = \"./models/crf.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size=VOCAB_SIZE, n_classes=LABELS_SIZE, embedding_dim=EMBEDDING_DIM, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS):\n",
    "        \"\"\"\n",
    "        The constructor of our RNN model\n",
    "        Inputs:\n",
    "        - vacab_size: the number of unique characters\n",
    "        - embedding_dim: the embedding dimension\n",
    "        - n_classes: the number of final classes (diacritics)\n",
    "        \"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        # (1) Create an embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # (2) Create an LSTM layer with hidden size = hidden_size and batch_first = True\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # (3) Create a linear layer with number of neorons = n_classes\n",
    "        self.linear = nn.Linear(hidden_size * 2, n_classes)\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        \"\"\"\n",
    "        This function does the forward pass of our model\n",
    "        Inputs:\n",
    "        - sentences: tensor of shape (batch_size, max_length)\n",
    "\n",
    "        Returns:\n",
    "        - final_output: tensor of shape (batch_size, max_length, n_classes)\n",
    "        \"\"\"\n",
    "\n",
    "        final_output = None\n",
    "        \n",
    "        embeddings = self.embedding(sentences)\n",
    "        lstm_out, _ = self.lstm(embeddings)\n",
    "        output = self.linear(lstm_out)\n",
    "        # final_output = F.softmax(output, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size=VOCAB_SIZE, num_classes=LABELS_SIZE, embedding_dim=EMBEDDING_DIM, filter_sizes=[3, 4, 5], num_filters=[100, 100, 100], dropout=0.5):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Conv Network\n",
    "        self.conv1d_list = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=embedding_dim,\n",
    "                      out_channels=num_filters[i],\n",
    "                      kernel_size=filter_sizes[i])\n",
    "            for i in range(len(filter_sizes))\n",
    "        ])\n",
    "        \n",
    "        # Fully-connected layer and Dropout\n",
    "        self.fc = nn.Linear(np.sum(num_filters), num_classes)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        # Get embeddings from `input_ids`. Output shape: (b, max_len, embed_dim)\n",
    "        x_embed = self.embedding(input_ids).float()\n",
    "\n",
    "        # Permute `x_embed` to match input shape requirement of `nn.Conv1d`.\n",
    "        # Output shape: (b, embed_dim, max_len)\n",
    "        x_reshaped = x_embed.permute(0, 2, 1)\n",
    "\n",
    "        # Apply CNN and ReLU. Output shape: (b, num_filters[i], L_out)\n",
    "        x_conv_list = [F.relu(conv1d(x_reshaped)) for conv1d in self.conv1d_list]\n",
    "\n",
    "        # Max pooling. Output shape: (b, num_filters[i], 1)\n",
    "        x_pool_list = [F.max_pool1d(x_conv, kernel_size=x_conv.shape[2])\n",
    "            for x_conv in x_conv_list]\n",
    "        \n",
    "        # Concatenate x_pool_list to feed the fully connected layer.\n",
    "        # Output shape: (b, sum(num_filters))\n",
    "        x_fc = torch.cat([x_pool.squeeze(dim=2) for x_pool in x_pool_list],\n",
    "                         dim=1)\n",
    "        \n",
    "        # Compute logits. Output shape: (b, n_classes)\n",
    "        logits = self.fc(self.dropout(x_fc))\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_CRF(nn.Module):\n",
    "    def __init__(self, vocab_size=VOCAB_SIZE, n_classes=LABELS_SIZE, embedding_dim=EMBEDDING_DIM, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS):\n",
    "        super(LSTM_CRF, self).__init__()\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
    "\n",
    "        # Linear layer\n",
    "        self.linear = nn.Linear(hidden_size * 2, n_classes)\n",
    "\n",
    "        # CRF layer\n",
    "        self.crf = CRF(n_classes)  # Place the CRF layer after the linear layer\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        embeddings = self.embedding(sentences)\n",
    "        lstm_out, _ = self.lstm(embeddings)\n",
    "        output = self.linear(lstm_out)\n",
    "        return output  # Return raw output for CRF loss calculation\n",
    "\n",
    "    def predict(self, sentences):\n",
    "        output = self.forward(sentences)\n",
    "        predictions = self.crf.decode(output)\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "def train(model, path, train_dataset, train_labels, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, learning_rate=LEARNING_RATE):\n",
    "    \"\"\"\n",
    "    This function implements the training logic\n",
    "    Inputs:\n",
    "    - model: the model to be trained\n",
    "    - train_dataset: the training set\n",
    "    - batch_size: integer represents the number of examples per step\n",
    "    - epochs: integer represents the total number of epochs (full training pass)\n",
    "    - learning_rate: the learning rate to be used by the optimizer\n",
    "    \"\"\"\n",
    "\n",
    "    # (1) create the dataloader of the training set (make the shuffle=True)\n",
    "    tensor_train_dataset = TensorDataset(train_dataset, train_labels)\n",
    "    train_dataloader = DataLoader(tensor_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # (2) make the criterion cross entropy loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # (3) create the optimizer (Adam)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # (4) create a learning rate scheduler (optional but recommended)\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.1)  # Adjust parameters as needed\n",
    "\n",
    "    # GPU configuration\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "    for epoch_num in range(epochs):\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "        \n",
    "        for train_input, train_label in tqdm(train_dataloader):\n",
    "            # Zero your gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Move the train input to the device\n",
    "            train_label = train_label.to(device)\n",
    "\n",
    "            # Move the train label to the device\n",
    "            train_input = train_input.to(device)\n",
    "\n",
    "            # Do the forward pass\n",
    "            output = model(train_input).float()\n",
    "\n",
    "            # Loss calculation\n",
    "            batch_loss = criterion(output.view(-1, output.shape[-1]), train_label.view(-1))\n",
    "\n",
    "            # Append the batch loss to the total_loss_train\n",
    "            total_loss_train += batch_loss.item()\n",
    "            \n",
    "            # Calculate the batch accuracy (just add the number of correct predictions)\n",
    "            # Compare predicted diacritic with true diacritic and count correct predictions\n",
    "            correct_predictions = (output.argmax(dim=2) == train_label)\n",
    "\n",
    "            # Calculate accuracy for the current batch\n",
    "            acc = correct_predictions.sum().item()\n",
    "            total_acc_train += acc\n",
    "\n",
    "            # Do the backward pass\n",
    "            batch_loss.backward()\n",
    "\n",
    "            # Update the weights with your optimizer\n",
    "            optimizer.step()     \n",
    "        # Step the learning rate scheduler\n",
    "        scheduler.step()\n",
    "        # Calculate the epoch loss\n",
    "        epoch_loss = total_loss_train / len(train_dataset)\n",
    "\n",
    "        # Calculate the accuracy\n",
    "        epoch_acc = total_acc_train / (len(train_dataset) * len(train_dataset[0]))\n",
    "\n",
    "        print(f'Epochs: {epoch_num + 1} | Train Loss: {epoch_loss} \\\n",
    "            | Train Accuracy: {epoch_acc}\\n')\n",
    "        \n",
    "        if epoch_acc > best_accuracy:\n",
    "            best_accuracy = epoch_acc\n",
    "            torch.save(model.state_dict(), path)\n",
    "            print(f'Saved the best model with accuracy: {best_accuracy} to {path}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=  readFile(TRAIN_PATH)\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for sentence in corpus[:1000]:\n",
    "\t# Clean each sentence in the corpus\n",
    "\t# Get the char list for each word in the sentence and its corresponding diacritics\n",
    "\tchar_list, diacritics_list = separate_words_and_diacritics(sentence.strip())\n",
    "\n",
    "\tx_train.append(char_list)\n",
    "\ty_train.append(diacritics_list)\n",
    "\n",
    "X_train_padded = [torch.tensor([char_to_index[char] for char in word]) for sentence in x_train for word in sentence]\n",
    "X_train_padded = pad_sequence(X_train_padded, batch_first=True)\n",
    "\n",
    "y_train_padded = [torch.tensor([diacritic_to_index[char] for char in word]) for sentence in y_train for word in sentence]\n",
    "y_train_padded = pad_sequence(y_train_padded, batch_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_RNN():\n",
    "    model=RNN()\n",
    "    print(model)\n",
    "    train(model, LSTM_PATH, X_train_padded, y_train_padded)\n",
    "    \n",
    "def run_CNN():\n",
    "    model=CNN()\n",
    "    print(model)\n",
    "    train(model, CNN_PATH, X_train_padded, y_train_padded)\n",
    "\n",
    "def run_CRF():\n",
    "    model=LSTM_CRF()\n",
    "    print(model)\n",
    "    train(model, CRF_PATH, X_train_padded, y_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (embedding): Embedding(37, 200)\n",
      "  (conv1d_list): ModuleList(\n",
      "    (0): Conv1d(200, 100, kernel_size=(3,), stride=(1,))\n",
      "    (1): Conv1d(200, 100, kernel_size=(4,), stride=(1,))\n",
      "    (2): Conv1d(200, 100, kernel_size=(5,), stride=(1,))\n",
      "  )\n",
      "  (fc): Linear(in_features=300, out_features=15, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/179 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (256) to match target batch_size (2816).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[163], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# run_RNN()\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mrun_CNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# run_CRF()\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[162], line 9\u001b[0m, in \u001b[0;36mrun_CNN\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m=\u001b[39mCNN()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCNN_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_padded\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[160], line 53\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, path, train_dataset, train_labels, batch_size, epochs, learning_rate)\u001b[0m\n\u001b[0;32m     50\u001b[0m output \u001b[38;5;241m=\u001b[39m model(train_input)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Loss calculation\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Append the batch loss to the total_loss_train\u001b[39;00m\n\u001b[0;32m     56\u001b[0m total_loss_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\functional.py:3053\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3052\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (256) to match target batch_size (2816)."
     ]
    }
   ],
   "source": [
    "# run_RNN()\n",
    "run_CNN()\n",
    "# run_CRF()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
