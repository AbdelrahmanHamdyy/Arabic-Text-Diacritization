{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "%run preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_SIZE = 512\n",
    "NUM_LAYERS = 2\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 200\n",
    "VOCAB_SIZE = len(basic_arabic_letters) + 1\n",
    "LABELS_SIZE = len(DIACRITICS)\n",
    "PAD = 15\n",
    "CONTEXTUAL_EMBEDDING_DIM=300\n",
    "\n",
    "TRAIN_PATH = \"./dataset/train.txt\"\n",
    "VAL_PATH = \"./dataset/val.txt\"\n",
    "TEST_PATH = \"./dataset/test.txt\"\n",
    "LSTM_PATH=\"./models/lstm.pth\"\n",
    "RNN_PATH=\"./models/rnn.pth\"\n",
    "CNN_PATH = \"./models/cnn.pth\"\n",
    "CRF_PATH = \"./models/crf.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "device = None\n",
    "device_type = None\n",
    "if torch.cuda.is_available():\n",
    "    device_type = \"cuda\"\n",
    "    device = torch.device(device_type)\n",
    "    print(f\"There are {torch.cuda.device_count()} GPU(s) available.\")\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    device_type = \"cpu\"\n",
    "    device = torch.device(device_type)\n",
    "    print(\"No GPU available, using the CPU instead.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size=VOCAB_SIZE, num_classes=LABELS_SIZE, embedding_dim=EMBEDDING_DIM, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS\n",
    "                , pretrained_embedding=None, freeze_embedding=False,contextual_embedding_dim=CONTEXTUAL_EMBEDDING_DIM):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Embedding layer\n",
    "        if pretrained_embedding is not None:\n",
    "            self.embedding  = nn.Embedding.from_pretrained(pretrained_embedding, freeze=freeze_embedding)\n",
    "        else:\n",
    "            self.embedding =nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Convolutional Layer\n",
    "        self.conv1d = nn.Conv1d(contextual_embedding_dim, 256, kernel_size=3, padding=1)\n",
    "        \n",
    "        # LSTM Layer\n",
    "        self.lstm = nn.LSTM(256, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # Linear Layer\n",
    "        self.linear = nn.Linear(2 * hidden_size, num_classes).float()\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        embeddings = self.embedding(sentences)\n",
    "        # if self.contextual_embedding is not None:\n",
    "        #     embeddings = torch.cat([embeddings, self.contextual_embedding(sentences)], dim=2)  # Concatenate embeddings\n",
    "        # Convolutional Layer\n",
    "        conv_out = self.conv1d(embeddings.permute(0, 2, 1))\n",
    "        conv_out = F.relu(conv_out)\n",
    "        \n",
    "        # LSTM Layer\n",
    "        lstm_out, _ = self.lstm(conv_out.permute(0, 2, 1))\n",
    "        \n",
    "        # Linear Layer\n",
    "        output = self.linear(lstm_out)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(\n",
    "    train_inputs, val_inputs, train_labels, val_labels, batch_size=BATCH_SIZE\n",
    "):\n",
    "    # Create DataLoader for training data\n",
    "    train_data = TensorDataset(train_inputs, train_labels)\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(\n",
    "        train_data, sampler=train_sampler, batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    # Create DataLoader for validation data\n",
    "    val_data = TensorDataset(val_inputs, val_labels)\n",
    "    val_sampler = SequentialSampler(val_data)\n",
    "    val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "\n",
    "    return train_dataloader, val_dataloader\n",
    "\n",
    "\n",
    "# Specify loss function\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "\n",
    "\n",
    "def train(\n",
    "    path, model, optimizer, train_dataloader, val_dataloader=None, epochs=NUM_EPOCHS\n",
    "):\n",
    "    \"\"\"Train the model\"\"\"\n",
    "\n",
    "    # Tracking best validation accuracy\n",
    "    best_accuracy = 0\n",
    "\n",
    "    # Start training loop\n",
    "    print(\"Start training...\\n\")\n",
    "    print(\n",
    "        f\"{'Epoch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\"\n",
    "    )\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        # =======================================\n",
    "        #               Training\n",
    "        # =======================================\n",
    "\n",
    "        # Tracking time and loss\n",
    "        t0_epoch = time.time()\n",
    "        total_loss = 0\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            # Load batch to GPU\n",
    "            b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Perform a forward pass\n",
    "            output = model(b_input_ids)\n",
    "\n",
    "            # Compute loss and accumulate the loss values\n",
    "            loss = loss_fn(output.view(-1, output.shape[-1]), b_labels.view(-1))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        # =======================================\n",
    "        #               Evaluation\n",
    "        # =======================================\n",
    "        if val_dataloader is not None:\n",
    "            # After the completion of each training epoch, measure the model's\n",
    "            # performance on our validation set.\n",
    "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "\n",
    "            # Track the best accuracy\n",
    "            if val_accuracy > best_accuracy:\n",
    "                best_accuracy = val_accuracy\n",
    "                torch.save(model.state_dict(), path)\n",
    "\n",
    "            # Print performance over the entire training data\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "            print(\n",
    "                f\"{epoch_i + 1:^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\"\n",
    "            )\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(f\"Training complete! Best accuracy: {best_accuracy:.2f}%.\")\n",
    "\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    \"\"\"\n",
    "    After the completion of each training epoch, measure the model's\n",
    "    performance on our validation set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    val_loss = []\n",
    "    val_accuracy = []\n",
    "\n",
    "    # For each batch in our validation set...\n",
    "    for batch in val_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Filter out the padding value\n",
    "        labels_without_pad = (b_labels != PAD)\n",
    "\n",
    "        # Get the output\n",
    "        with torch.no_grad():\n",
    "            output = model(b_input_ids)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(output.view(-1, output.shape[-1]), b_labels.view(-1))\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        # Get the predictions\n",
    "        preds = output.argmax(dim=2)\n",
    "\n",
    "        # Calculate the accuracy\n",
    "        correct_predictions = ((preds == b_labels) & labels_without_pad).sum().item()\n",
    "        actual_predictions = labels_without_pad.sum().item()\n",
    "        accuracy = (correct_predictions / actual_predictions) * 100\n",
    "\n",
    "        val_accuracy.append(accuracy)\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'camembert-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "t_model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2embed(sentence, model=t_model, tokenizer=tokenizer):\n",
    "    # Tokenize and obtain contextual embeddings\n",
    "    tokens = tokenizer(sentence, return_tensors='pt')\n",
    "    outputs = model(**tokens)\n",
    "\n",
    "    # The last layer hidden states often contain contextual embeddings\n",
    "    contextual_embeddings = outputs.last_hidden_state\n",
    "\n",
    "    # Apply global average pooling (GAP) along the sequence dimension\n",
    "    global_avg_pooled_embedding = torch.mean(contextual_embeddings, dim=1)\n",
    "\n",
    "    # If necessary, apply linear transformation to get embeddings of size 100\n",
    "    desired_embedding_size = CONTEXTUAL_EMBEDDING_DIM\n",
    "    linear_layer = torch.nn.Linear(global_avg_pooled_embedding.size(-1), desired_embedding_size)\n",
    "    transformed_embedding = linear_layer(global_avg_pooled_embedding)\n",
    "\n",
    "    # Apply activation function (e.g., ReLU)\n",
    "    transformed_embedding = torch.relu(transformed_embedding)\n",
    "    return transformed_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "aravec_embeddings_train = []\n",
    "train_corpus = readFile(TRAIN_PATH)\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "X_val = []\n",
    "Y_val = []\n",
    "\n",
    "for sentence in train_corpus[:100]:\n",
    "    # Clean each sentence in the corpus\n",
    "    # Get the char list for each word in the sentence and its corresponding diacritics\n",
    "    char_list, diacritics_list = separate_words_and_diacritics(sentence.strip())\n",
    "    for i in range(len(char_list)):\n",
    "        X_train.append(char_list[i])\n",
    "        aravec_embeddings_train.append(word2embed(''.join(char_list[i]))[0].tolist())\n",
    "        Y_train.append(diacritics_list[i])\n",
    "\n",
    "X_train_padded = [torch.tensor([char_to_index[char] for char in sentence]) for sentence in X_train]\n",
    "X_train_padded = pad_sequence(X_train_padded, batch_first=True)\n",
    "\n",
    "y_train_padded = [torch.tensor([diacritic_to_index[char] for char in sentence]) for sentence in Y_train]\n",
    "y_train_padded = pad_sequence(y_train_padded, batch_first=True, padding_value=PAD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "aravec_embeddings_val = []\n",
    "\n",
    "val_corpus = readFile(VAL_PATH)\n",
    "\n",
    "for sentence in val_corpus[:5]:\n",
    "    # Clean each sentence in the corpus\n",
    "    # Get the char list for each word in the sentence and its corresponding diacritics\n",
    "    char_list, diacritics_list = separate_words_and_diacritics(sentence.strip())\n",
    "\n",
    "    for i in range(len(char_list)):\n",
    "        X_val.append(char_list[i])\n",
    "        aravec_embeddings_val.append(word2embed(''.join(char_list[i]))[0].tolist())\n",
    "        Y_val.append(diacritics_list[i])\n",
    "\n",
    "x_val_padded = [torch.tensor([char_to_index[char] for char in sentence]) for sentence in X_val]\n",
    "x_val_padded = pad_sequence(x_val_padded, batch_first=True)\n",
    "\n",
    "y_val_padded = [torch.tensor([diacritic_to_index[char] for char in sentence]) for sentence in Y_val]\n",
    "y_val_padded = pad_sequence(y_val_padded, batch_first=True, padding_value=PAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(learning_rate=LEARNING_RATE):\n",
    "    model = CNN(pretrained_embedding=torch.tensor(aravec_embeddings_train+aravec_embeddings_val), freeze_embedding=True)\n",
    "    path = CNN_PATH\n",
    "\n",
    "    # Send model to `device` (GPU/CPU)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Instantiate the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    return path, model, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (embedding): Embedding(121, 300)\n",
      "  (conv1d): Conv1d(300, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (lstm): LSTM(256, 512, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=1024, out_features=15, bias=True)\n",
      ")\n",
      "Start training...\n",
      "\n",
      " Epoch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   1    |   2.701133   |  2.576483  |   35.76   |   84.82  \n",
      "   2    |   2.577816   |  2.348295  |   35.76   |   84.56  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[0;32m      3\u001b[0m train_dataloader, val_dataloader \u001b[38;5;241m=\u001b[39m data_loader(X_train_padded, x_val_padded, y_train_padded, y_val_padded)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(path, model, optimizer, train_dataloader, val_dataloader, epochs)\u001b[0m\n\u001b[0;32m     62\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Perform a backward pass to calculate gradients\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Update parameters\u001b[39;00m\n\u001b[0;32m     68\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path, model, optimizer = init_model()\n",
    "print(model)\n",
    "train_dataloader, val_dataloader = data_loader(X_train_padded, x_val_padded, y_train_padded, y_val_padded)\n",
    "train(path, model, optimizer, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.12717025950352 | DER: 0.03872829740496486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_corpus = readFile(TEST_PATH)\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for sentence in test_corpus:\n",
    "    char_list, diacritics_list = separate_words_and_diacritics(sentence.strip())\n",
    "\n",
    "    for i in range(len(char_list)):\n",
    "        x_test.append(char_list[i])\n",
    "        y_test.append(diacritics_list[i])\n",
    "\n",
    "x_test_padded = [torch.tensor([char_to_index[char] for char in sentence]) for sentence in x_test]\n",
    "x_test_padded = pad_sequence(x_test_padded, batch_first=True)\n",
    "\n",
    "y_test_padded = [torch.tensor([diacritic_to_index[char] for char in sentence]) for sentence in y_test]\n",
    "y_test_padded = pad_sequence(y_test_padded, batch_first=True, padding_value=PAD)\n",
    "\n",
    "test_data = TensorDataset(x_test_padded, y_test_padded)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "model = CNN()\n",
    "model.load_state_dict(torch.load(CNN_PATH, map_location=torch.device(device_type)))\n",
    "model.to(device)\n",
    "\n",
    "loss, acc = evaluate(model, test_dataloader)\n",
    "\n",
    "print(f'Accuracy: {acc} | DER: {1 - (acc / 100)}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
