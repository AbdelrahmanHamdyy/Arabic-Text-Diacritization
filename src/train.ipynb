{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ق', 'و', 'ل', 'ه'], ['ل', 'ع', 'د', 'م'], ['م', 'ا'], ['ت', 'ت', 'ع', 'ل', 'ق'], ['إ', 'ل', 'خ'], ['أ', 'ي'], ['ا', 'ل', 'و', 'ص', 'ي', 'ة'], ['ق', 'و', 'ل', 'ه'], ['م', 'ا'], ['م', 'ر'], ['أ', 'ي'], ['ق', 'ب', 'ي', 'ل'], ['ق', 'و', 'ل'], ['ا', 'ل', 'م', 'ت', 'ن'], ['ل', 'غ', 'ت'], ['و', 'ل', 'و'], ['ا', 'ق', 'ت', 'ص', 'ر'], ['ع', 'ل', 'ى'], ['أ', 'و', 'ص', 'ي', 'ت'], ['ل', 'ه'], ['ب', 'ش', 'ا', 'ة'], ['أ', 'و'], ['أ', 'ع', 'ط', 'و', 'ه'], ['ش', 'ا', 'ة'], ['و', 'ل', 'ا'], ['غ', 'ن', 'م'], ['ل', 'ه'], ['ع', 'ن', 'د'], ['ا', 'ل', 'م', 'و', 'ت'], ['ه', 'ل'], ['ت', 'ب', 'ط', 'ل'], ['ا', 'ل', 'و', 'ص', 'ي', 'ة'], ['أ', 'و'], ['ي', 'ش', 'ت', 'ر', 'ى'], ['ل', 'ه'], ['ش', 'ا', 'ة'], ['و', 'ي', 'ؤ', 'خ', 'ذ'], ['م', 'ن'], ['ق', 'و', 'ل', 'ه'], ['ا', 'ل', 'آ', 'ت', 'ي'], ['ك', 'م', 'ا'], ['ل', 'و'], ['ل', 'م'], ['ي', 'ق', 'ل'], ['م', 'ن'], ['م', 'ا', 'ل', 'ي'], ['و', 'ل', 'ا'], ['م', 'ن'], ['غ', 'ن', 'م', 'ي'], ['أ', 'ن', 'ه', 'ا'], ['ل', 'ا'], ['ت', 'ب', 'ط', 'ل'], ['و', 'ع', 'ب', 'ا', 'ر', 'ة'], ['ا', 'ل', 'ك', 'ن', 'ز'], ['و', 'ل', 'و'], ['ل', 'م'], ['ي', 'ق', 'ل'], ['م', 'ن'], ['م', 'ا', 'ل', 'ي'], ['و', 'ل', 'ا'], ['م', 'ن'], ['غ', 'ن', 'م', 'ي'], ['ل', 'م'], ['ي', 'ت', 'ع', 'ي', 'ن'], ['غ', 'ن', 'م', 'ه'], ['إ', 'ن'], ['ك', 'ا', 'ن', 'ت'], ['ا', 'ن', 'ت', 'ه', 'ت'], [], [], ['س', 'م'], ['ق', 'و', 'ل', 'ه'], ['ف', 'ي', 'ع', 'ط', 'ى'], ['و', 'ا', 'ح', 'د', 'ة'], ['م', 'ن', 'ه', 'ا'], ['إ', 'ل', 'خ'], ['ك', 'م', 'ا'], ['ل', 'و'], ['ك', 'ا', 'ن', 'ت'], ['م', 'و', 'ج', 'و', 'د', 'ة'], ['ع', 'ن', 'د'], ['ا', 'ل', 'و', 'ص', 'ي', 'ة'], ['و', 'ا', 'ل', 'م', 'و', 'ت'], ['و', 'ل', 'ا'], ['ي', 'ج', 'و', 'ز'], ['أ', 'ن'], ['ي', 'ع', 'ط', 'ى'], ['و', 'ا', 'ح', 'د', 'ة'], ['م', 'ن'], ['غ', 'ي', 'ر'], ['غ', 'ن', 'م', 'ه'], ['ف', 'ي'], ['ا', 'ل', 'ص', 'و', 'ر', 'ت', 'ي', 'ن'], ['و', 'إ', 'ن'], ['ت', 'ر', 'ا', 'ض', 'ي', 'ا'], ['ل', 'أ', 'ن', 'ه'], ['ص', 'ل', 'ح'], ['ع', 'ل', 'ى'], ['م', 'ج', 'ه', 'و', 'ل'], ['م', 'غ', 'ن', 'ي'], ['و', 'ن', 'ه', 'ا', 'ي', 'ة'], ['ق', 'ا', 'ل'], [], [], ['ق', 'و', 'ل', 'ه'], ['و', 'ا', 'ح', 'د', 'ة'], ['م', 'ن', 'ه', 'ا'], ['أ', 'ي'], ['ك', 'ا', 'م', 'ل', 'ة'], ['و', 'ل', 'ا'], ['ي', 'ج', 'و', 'ز'], ['أ', 'ن'], ['ي', 'ع', 'ط', 'ى'], ['ن', 'ص', 'ف', 'ي', 'ن'], ['م', 'ن'], ['ش', 'ا', 'ت', 'ي', 'ن'], ['ل', 'أ', 'ن', 'ه'], ['ل', 'ا'], ['ي', 'س', 'م', 'ى'], ['ش', 'ا', 'ة'], ['و', 'ق', 'و', 'ل', 'ه'], ['و', 'ل', 'ا'], ['ي', 'ج', 'و', 'ز'], ['أ', 'ن'], ['ي', 'ع', 'ط', 'ى'], ['و', 'ا', 'ح', 'د', 'ة'], ['م', 'ن'], ['غ', 'ي', 'ر'], ['غ', 'ن', 'م', 'ه'], ['و', 'ي', 'ن', 'ب', 'غ', 'ي'], ['أ', 'ن'], ['ي', 'ق', 'ا', 'ل'], ['م', 'ث', 'ل'], ['ذ', 'ل', 'ك'], ['ف', 'ي'], ['ا', 'ل', 'أ', 'ر', 'ق', 'ا', 'ء'], [], []]\n",
      "[['َ', 'ْ', 'ُ', 'ُ'], ['ِ', 'َ', 'َ', 'ِ'], ['َ', ' '], ['َ', 'َ', 'َ', 'َّ', 'ُ'], [' ', 'َ', 'ْ'], ['َ', 'ْ'], [' ', 'ْ', 'َ', 'ِ', 'َّ', 'ُ'], ['َ', 'ْ', 'ُ', 'ُ'], ['َ', ' '], ['َ', 'َّ'], ['َ', 'ْ'], ['ُ', 'َ', 'ْ', 'َ'], ['َ', 'ْ', 'ِ'], [' ', 'ْ', 'َ', 'ْ', 'ِ'], ['َ', 'َ', 'ْ'], ['َ', 'َ', 'ْ'], [' ', 'ْ', 'َ', 'َ', 'َ'], ['َ', 'َ', ' '], ['َ', 'ْ', 'َ', 'ْ', ' '], ['َ', 'ُ'], ['ِ', 'َ', ' ', 'ٍ'], ['َ', 'ْ'], ['َ', 'ْ', 'ُ', ' ', 'ُ'], ['َ', ' ', 'ً'], ['َ', 'َ', ' '], ['َ', 'َ', 'َ'], ['َ', 'ُ'], ['ِ', 'ْ', 'َ'], [' ', 'ْ', 'َ', 'ْ', 'ِ'], ['َ', 'ْ'], ['َ', 'ْ', 'ُ', 'ُ'], [' ', 'ْ', 'َ', 'ِ', 'َّ', 'ُ'], ['َ', 'ْ'], ['ُ', 'ْ', 'َ', 'َ', ' '], ['َ', 'ُ'], ['َ', ' ', 'ٌ'], ['َ', 'ُ', 'ْ', 'َ', 'ُ'], ['ِ', 'ْ'], ['َ', 'ْ', 'ِ', 'ِ'], [' ', 'ْ', ' ', 'ِ', ' '], ['َ', 'َ', ' '], ['َ', 'ْ'], ['َ', 'ْ'], ['َ', 'ُ', 'ْ'], ['ِ', 'ْ'], ['َ', ' ', 'ِ', ' '], ['َ', 'َ', ' '], ['ِ', 'ْ'], ['َ', 'َ', 'ِ', ' '], ['َ', 'َّ', 'َ', ' '], ['َ', ' '], ['َ', 'ْ', 'ُ', 'ُ'], ['َ', 'ِ', 'َ', ' ', 'َ', 'ُ'], [' ', 'ْ', 'َ', 'ْ', 'ِ'], ['َ', 'َ', 'ْ'], ['َ', 'ْ'], ['َ', 'ُ', 'ْ'], ['ِ', 'ْ'], ['َ', ' ', 'ِ', ' '], ['َ', 'َ', ' '], ['ِ', 'ْ'], ['َ', 'َ', 'ِ', ' '], ['َ', 'ْ'], ['َ', 'َ', 'َ', 'َّ', 'ْ'], ['َ', 'َ', 'ُ', 'ُ'], [' ', 'ْ'], ['َ', ' ', 'َ', 'ْ'], [' ', 'ْ', 'َ', 'َ', 'ْ'], [], [], [' ', ' '], ['َ', 'ْ', 'ُ', 'ُ'], ['َ', 'ُ', 'ْ', 'َ', ' '], ['َ', ' ', 'ِ', 'َ', 'ً'], ['ِ', 'ْ', 'َ', ' '], [' ', 'َ', 'ْ'], ['َ', 'َ', ' '], ['َ', 'ْ'], ['َ', ' ', 'َ', 'ْ'], ['َ', 'ْ', 'ُ', ' ', 'َ', 'ً'], ['ِ', 'ْ', 'َ'], [' ', 'ْ', 'َ', 'ِ', 'َّ', 'ِ'], ['َ', ' ', 'ْ', 'َ', 'ْ', 'ِ'], ['َ', 'َ', ' '], ['َ', 'ُ', ' ', 'ُ'], ['َ', 'ْ'], ['ُ', 'ْ', 'َ', ' '], ['َ', ' ', 'ِ', 'َ', 'ً'], ['ِ', 'ْ'], ['َ', 'ْ', 'ِ'], ['َ', 'َ', 'ِ', 'ِ'], ['ِ', ' '], [' ', ' ', 'ُّ', ' ', 'َ', 'َ', 'ْ', 'ِ'], ['َ', 'ِ', 'ْ'], ['َ', 'َ', ' ', 'َ', 'َ', ' '], ['ِ', 'َ', 'َّ', 'ُ'], ['ُ', 'ْ', 'ٌ'], ['َ', 'َ', ' '], ['َ', 'ْ', 'ُ', ' ', 'ٍ'], ['ُ', 'ْ', 'ِ', ' '], ['َ', 'ِ', 'َ', ' ', 'َ', 'ٌ'], ['َ', ' ', 'َ'], [], [], ['َ', 'ْ', 'ُ', 'ُ'], ['َ', ' ', 'ِ', 'َ', 'ً'], ['ِ', 'ْ', 'َ', ' '], ['َ', 'ْ'], ['َ', ' ', 'ِ', 'َ', 'ً'], ['َ', 'َ', ' '], ['َ', 'ُ', ' ', 'ُ'], ['َ', 'ْ'], ['ُ', 'ْ', 'َ', ' '], ['ِ', 'ْ', 'َ', 'ْ', 'ِ'], ['ِ', 'ْ'], ['َ', ' ', 'َ', 'ْ', 'ِ'], ['ِ', 'َ', 'َّ', 'ُ'], ['َ', ' '], ['ُ', 'َ', 'َّ', ' '], ['َ', ' ', 'ً'], ['َ', 'َ', 'ْ', 'ُ', 'ُ'], ['َ', 'َ', ' '], ['َ', 'ُ', ' ', 'ُ'], ['َ', 'ْ'], ['ُ', 'ْ', 'َ', ' '], ['َ', ' ', 'ِ', 'َ', 'ً'], ['ِ', 'ْ'], ['َ', 'ْ', 'ِ'], ['َ', 'َ', 'ِ', 'ِ'], ['َ', 'َ', 'ْ', 'َ', 'ِ', ' '], ['َ', 'ْ'], ['ُ', 'َ', ' ', 'َ'], ['ِ', 'ْ', 'ُ'], ['َ', 'ِ', 'َ'], ['ِ', ' '], [' ', 'ْ', 'َ', 'ِ', 'َّ', ' ', 'ِ'], [], []]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "%run updatePreprocessing.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 200\n",
    "HIDDEN_SIZE = 512\n",
    "NUM_LAYERS = 1\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 256\n",
    "VOCAB_SIZE = len(basic_arabic_letters) + 1\n",
    "LABELS_SIZE = len(DIACRITICS)\n",
    "\n",
    "\n",
    "TRAIN_PATH = \"../dataset/train.txt\"\n",
    "VAL_PATH = \"../dataset/val.txt\"\n",
    "LSTM_PATH=\"./models/lstm.pth\"\n",
    "RNN_PATH=\"./models/rnn.pth\"\n",
    "CBHG_PATH=\"./models/cbhg.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class Prenet(nn.Module):\n",
    "    \"\"\"\n",
    "    A prenet is a collection of linear layers with dropout(0.5),\n",
    "    and RELU activation function\n",
    "    Args:\n",
    "    config: the hyperparameters object\n",
    "    in_dim (int): the input dim\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, in_dim: int, prenet_depth: List[int] = [256, 128], dropout: int = 0.5\n",
    "    ):\n",
    "        \"\"\" Initializing the prenet module \"\"\"\n",
    "        super().__init__()\n",
    "        in_sizes = [in_dim] + prenet_depth[:-1]\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                nn.Linear(in_size, out_size)\n",
    "                for (in_size, out_size) in zip(in_sizes, prenet_depth)\n",
    "            ]\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor):\n",
    "        \"\"\"Calculate forward propagation\n",
    "        Args:\n",
    "        inputs (batch_size, seqLen): the inputs to the prenet, the input shapes could\n",
    "        be different as it is being used in both encoder and decoder.\n",
    "        Returns:\n",
    "        Tensor: the output of  the forward propagation\n",
    "        \"\"\"\n",
    "        for linear in self.layers:\n",
    "            inputs = self.dropout(self.relu(linear(inputs)))\n",
    "        return inputs\n",
    "class Highway(nn.Module):\n",
    "    \"\"\"Highway Networks were developed by (Srivastava et al., 2015)\n",
    "    to overcome the difficulty of training deep neural networks\n",
    "    (https://arxiv.org/abs/1507.06228).\n",
    "    Args:\n",
    "    in_size (int): the input size\n",
    "    out_size (int): the output size\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_size, out_size):\n",
    "        \"\"\"\n",
    "        Initializing Highway networks\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.H = nn.Linear(in_size, out_size)\n",
    "        self.H.bias.data.zero_()\n",
    "        self.T = nn.Linear(in_size, out_size)\n",
    "        self.T.bias.data.fill_(-1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor):\n",
    "        \"\"\"Calculate forward propagation\n",
    "        Args:\n",
    "        inputs (Tensor):\n",
    "        \"\"\"\n",
    "        H = self.relu(self.H(inputs))\n",
    "        T = self.sigmoid(self.T(inputs))\n",
    "        return H * T + inputs * (1.0 - T)\n",
    "class BatchNormConv1d(nn.Module):\n",
    "    \"\"\"\n",
    "    A nn.Conv1d followed by an optional activation function, and nn.BatchNorm1d\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        out_dim: int,\n",
    "        kernel_size: int,\n",
    "        stride: int,\n",
    "        padding: int,\n",
    "        activation = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv1d = nn.Conv1d(\n",
    "            in_dim,\n",
    "            out_dim,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm1d(out_dim)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1d(x)\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "        return self.bn(x)\n",
    "class CBHG(nn.Module):\n",
    "    \"\"\"The CBHG module (1-D Convolution Bank + Highway network + Bidirectional GRU)\n",
    "    was proposed by (Lee et al., 2017, https://www.aclweb.org/anthology/Q17-1026)\n",
    "    for a character-level NMT model.\n",
    "    It was adapted by (Wang et al., 2017) for building the Tacotron.\n",
    "    It is used in both the encoder and decoder  with different parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        out_dim: int,\n",
    "        K: int,\n",
    "        projections,\n",
    "        highway_layers: int = 4,\n",
    "    ):\n",
    "        \"\"\"Initializing the CBHG module\n",
    "        Args:\n",
    "        in_dim (int): the input size\n",
    "        out_dim (int): the output size\n",
    "        k (int): number of filters\n",
    "        projections: A list of integers representing the output sizes of convolutional projections.\n",
    "        highway_layers: Number of highway layers.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.relu = nn.ReLU()\n",
    "        #list of modules each one of them will be BatchNoemConv1 \n",
    "        #and each of them has a kernel size ranging from 1 -> k\n",
    "        self.conv1d_banks = nn.ModuleList(\n",
    "            [\n",
    "                BatchNormConv1d(\n",
    "                    in_dim,\n",
    "                    in_dim,\n",
    "                    kernel_size=k,\n",
    "                    stride=1,\n",
    "                    padding=k // 2,\n",
    "                    activation=self.relu,\n",
    "                )\n",
    "                for k in range(1, K + 1)\n",
    "            ]\n",
    "        )\n",
    "        '''\n",
    "        kernel_size: The size of the window over which the maximum value is computed. It specifies the size of the pooling operation.\n",
    "        stride: The step size to slide the pooling window along the input. If not specified, it defaults to kernel_size.\n",
    "        padding: Zero-padding added to both sides of the input. Padding helps to control the spatial dimensions of the output.\n",
    "        '''\n",
    "        self.max_pool1d = nn.MaxPool1d(kernel_size=2, stride=1, padding=1)\n",
    "\n",
    "        in_sizes = [K * in_dim] + projections[:-1]\n",
    "        activations = [self.relu] * (len(projections) - 1) + [None]\n",
    "        self.conv1d_projections = nn.ModuleList(\n",
    "            [\n",
    "                BatchNormConv1d(\n",
    "                    in_size, out_size, kernel_size=3, stride=1, padding=1, activation=ac\n",
    "                )\n",
    "                for (in_size, out_size, ac) in zip(in_sizes, projections, activations)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.pre_highway = nn.Linear(projections[-1], in_dim, bias=False)\n",
    "        self.highways = nn.ModuleList([Highway(in_dim, in_dim) for _ in range(4)])\n",
    "\n",
    "        self.gru = nn.GRU(in_dim, out_dim, 1, batch_first=True, bidirectional=True)\n",
    "\n",
    "    def forward(self, inputs, input_lengths=None):\n",
    "        # (B, T_in, in_dim)\n",
    "        x = inputs\n",
    "        x = x.transpose(1, 2)\n",
    "        T = x.size(-1)\n",
    "\n",
    "        # (B, in_dim*K, T_in)\n",
    "        # Concat conv1d bank outputs\n",
    "        x = torch.cat([conv1d(x)[:, :, :T] for conv1d in self.conv1d_banks], dim=1)\n",
    "        assert x.size(1) == self.in_dim * len(self.conv1d_banks)\n",
    "        x = self.max_pool1d(x)[:, :, :T]\n",
    "\n",
    "        for conv1d in self.conv1d_projections:\n",
    "            x = conv1d(x)\n",
    "\n",
    "        # (B, T_in, in_dim)\n",
    "        # Back to the original shape\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        if x.size(-1) != self.in_dim:\n",
    "            x = self.pre_highway(x)\n",
    "\n",
    "        # Residual connection\n",
    "        x += inputs\n",
    "        for highway in self.highways:\n",
    "            x = highway(x)\n",
    "\n",
    "        if input_lengths is not None:\n",
    "            x = nn.utils.rnn.pack_padded_sequence(x, input_lengths, batch_first=True)\n",
    "\n",
    "        # (B, T_in, in_dim*2)\n",
    "        self.gru.flatten_parameters()\n",
    "        outputs, _ = self.gru(x)\n",
    "\n",
    "        if input_lengths is not None:\n",
    "            outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
    "\n",
    "        return outputs\n",
    "class CBHGModel(nn.Module):\n",
    "    \"\"\"CBHG model implementation as described in the paper:\n",
    "     https://ieeexplore.ieee.org/document/9274427\n",
    "\n",
    "    Args:\n",
    "    inp_vocab_size (int): the number of the input symbols\n",
    "    targ_vocab_size (int): the number of the target symbols (diacritics)\n",
    "    embedding_dim (int): the embedding  size\n",
    "    use_prenet (bool): whether to use prenet or not\n",
    "    prenet_sizes (List[int]): the sizes of the prenet networks\n",
    "    cbhg_gru_units (int): the number of units of the CBHG GRU, which is the last\n",
    "    layer of the CBHG Model.\n",
    "    cbhg_filters (int): number of filters used in the CBHG module\n",
    "    cbhg_projections: projections used in the CBHG module\n",
    "\n",
    "    Returns:\n",
    "    diacritics Dict[str, Tensor]:\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inp_vocab_size: int,\n",
    "        targ_vocab_size: int,\n",
    "        embedding_dim: int = 512,\n",
    "        use_prenet: bool = True,\n",
    "        prenet_sizes = [512, 256],\n",
    "        cbhg_gru_units: int = 512,\n",
    "        cbhg_filters: int = 16,\n",
    "        cbhg_projections = [128, 256],\n",
    "        post_cbhg_layers_units = [256, 256],\n",
    "        post_cbhg_use_batch_norm: bool = True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.use_prenet = use_prenet\n",
    "        self.embedding = nn.Embedding(inp_vocab_size, embedding_dim)\n",
    "        if self.use_prenet:\n",
    "            self.prenet = Prenet(embedding_dim, prenet_depth=prenet_sizes)\n",
    "\n",
    "        self.cbhg = CBHG(\n",
    "            prenet_sizes[-1] if self.use_prenet else embedding_dim,\n",
    "            cbhg_gru_units,\n",
    "            K=cbhg_filters,\n",
    "            projections=cbhg_projections,\n",
    "        )\n",
    "\n",
    "        layers = []\n",
    "        post_cbhg_layers_units = [cbhg_gru_units] + post_cbhg_layers_units\n",
    "\n",
    "        for i in range(1, len(post_cbhg_layers_units)):\n",
    "            layers.append(\n",
    "                nn.LSTM(\n",
    "                    post_cbhg_layers_units[i - 1] * 2,\n",
    "                    post_cbhg_layers_units[i],\n",
    "                    bidirectional=True,\n",
    "                    batch_first=True,\n",
    "                )\n",
    "            )\n",
    "            if post_cbhg_use_batch_norm:\n",
    "                layers.append(nn.BatchNorm1d(post_cbhg_layers_units[i] * 2))\n",
    "\n",
    "        self.post_cbhg_layers = nn.ModuleList(layers)\n",
    "        self.projections = nn.Linear(post_cbhg_layers_units[-1] * 2, targ_vocab_size)\n",
    "        self.post_cbhg_layers_units = post_cbhg_layers_units\n",
    "        self.post_cbhg_use_batch_norm = post_cbhg_use_batch_norm\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        src: torch.Tensor,\n",
    "        lengths = None,\n",
    "        target = None,  # not required in this model\n",
    "    ):\n",
    "        \"\"\"Compute forward propagation\"\"\"\n",
    "\n",
    "        # src = [batch_size, src len]\n",
    "        # lengths = [batch_size]\n",
    "        # target = [batch_size, trg len]\n",
    "\n",
    "        embedding_out = self.embedding(src)\n",
    "        # embedding_out; [batch_size, src_len, embedding_dim]\n",
    "\n",
    "        cbhg_input = embedding_out\n",
    "        if self.use_prenet:\n",
    "            cbhg_input = self.prenet(embedding_out)\n",
    "\n",
    "            # cbhg_input = [batch_size, src_len, prenet_sizes[-1]]\n",
    "\n",
    "        outputs = self.cbhg(cbhg_input, lengths)\n",
    "\n",
    "        hn = torch.zeros((2, 2, 2))\n",
    "        cn = torch.zeros((2, 2, 2))\n",
    "\n",
    "        for i, layer in enumerate(self.post_cbhg_layers):\n",
    "            if isinstance(layer, nn.BatchNorm1d):\n",
    "                outputs = layer(outputs.permute(0, 2, 1))\n",
    "                outputs = outputs.permute(0, 2, 1)\n",
    "                continue\n",
    "            if i > 0:\n",
    "                outputs, (hn, cn) = layer(outputs, (hn, cn))\n",
    "            else:\n",
    "                outputs, (hn, cn) = layer(outputs)\n",
    "\n",
    "\n",
    "        predictions = self.projections(outputs)\n",
    "\n",
    "        # predictions = [batch_size, src len, targ_vocab_size]\n",
    "\n",
    "        # output = {\"diacritics\": predictions}\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, path, train_dataset, train_labels, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, learning_rate=LEARNING_RATE):\n",
    "    \"\"\"\n",
    "    This function implements the training logic\n",
    "    Inputs:\n",
    "    - model: the model to be trained\n",
    "    - train_dataset: the training set\n",
    "    - batch_size: integer represents the number of examples per step\n",
    "    - epochs: integer represents the total number of epochs (full training pass)\n",
    "    - learning_rate: the learning rate to be used by the optimizer\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the dataloader of the training set (make the shuffle=True)\n",
    "    tensor_train_dataset = TensorDataset(train_dataset, train_labels)\n",
    "    train_dataloader = DataLoader(tensor_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Make the criterion cross entropy loss\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Create the optimizer (Adam)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # GPU configuration\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "    for epoch_num in range(epochs):\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "        \n",
    "        for train_input, train_label in tqdm(train_dataloader):\n",
    "            # Zero your gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Move the train input to the device\n",
    "            train_label = train_label.to(device)\n",
    "\n",
    "            # Move the train label to the device\n",
    "            train_input = train_input.to(device)\n",
    "\n",
    "            # Do the forward pass\n",
    "            output = model(train_input).float()\n",
    "\n",
    "            # Loss calculation\n",
    "            batch_loss = criterion(output.view(-1, output.shape[-1]), train_label.view(-1))\n",
    "\n",
    "            # Append the batch loss to the total_loss_train\n",
    "            total_loss_train += batch_loss.item()\n",
    "            \n",
    "            # Calculate the batch accuracy (just add the number of correct predictions)\n",
    "            # Compare predicted diacritic with true diacritic and count correct predictions\n",
    "            correct_predictions = (output.argmax(dim=2) == train_label)\n",
    "\n",
    "            # Calculate accuracy for the current batch\n",
    "            acc = correct_predictions.sum().item()\n",
    "            total_acc_train += acc\n",
    "\n",
    "            # Do the backward pass\n",
    "            batch_loss.backward()\n",
    "\n",
    "            # Update the weights with your optimizer\n",
    "            optimizer.step()     \n",
    "        \n",
    "        # Calculate the epoch loss\n",
    "        epoch_loss = total_loss_train / len(train_dataset)\n",
    "\n",
    "        # Calculate the accuracy\n",
    "        epoch_acc = total_acc_train / (len(train_dataset) * len(train_dataset[0]))\n",
    "\n",
    "        print(f'Epochs: {epoch_num + 1} | Train Loss: {epoch_loss} \\\n",
    "            | Train Accuracy: {epoch_acc}\\n')\n",
    "        \n",
    "        if epoch_acc > best_accuracy:\n",
    "            best_accuracy = epoch_acc\n",
    "            torch.save(model.state_dict(), path)\n",
    "            print(f'Saved the best model with accuracy: {best_accuracy} to {path}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(path):\n",
    "\tsentences = []\n",
    "\twith open(path, 'r', encoding='utf-8') as file:\n",
    "\t\tfor line in file:\n",
    "\t\t\tsentences.append(line.strip())\n",
    "\n",
    "\treturn sentences\n",
    "\n",
    "corpus=  readFile(TRAIN_PATH)\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for sentence in corpus[:100]:\n",
    "\t# Clean each sentence in the corpus\n",
    "\t# Get the char list for each word in the sentence and its corresponding diacritics\n",
    "\tchar_list, diacritics_list = separate_words_and_diacritics(sentence.strip())\n",
    "\n",
    "\tx_train.append(char_list)\n",
    "\ty_train.append(diacritics_list)\n",
    "\n",
    "X_train_padded = [torch.tensor([char_to_index[char] for char in word]) for sentence in x_train for word in sentence]\n",
    "X_train_padded = pad_sequence(X_train_padded, batch_first=True)\n",
    "\n",
    "y_train_padded = [torch.tensor([diacritic_to_index[char] for char in word]) for sentence in y_train for word in sentence]\n",
    "y_train_padded = pad_sequence(y_train_padded, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBHGModel(\n",
      "  (embedding): Embedding(37, 200)\n",
      "  (cbhg): CBHG(\n",
      "    (relu): ReLU()\n",
      "    (conv1d_banks): ModuleList(\n",
      "      (0): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(200, 200, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (1): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(200, 200, kernel_size=(2,), stride=(1,), padding=(1,), bias=False)\n",
      "        (bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (2): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(200, 200, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "        (bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (3): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(200, 200, kernel_size=(4,), stride=(1,), padding=(2,), bias=False)\n",
      "        (bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (4): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(200, 200, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      "        (bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (5): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(200, 200, kernel_size=(6,), stride=(1,), padding=(3,), bias=False)\n",
      "        (bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (6): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(200, 200, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
      "        (bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (7): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(200, 200, kernel_size=(8,), stride=(1,), padding=(4,), bias=False)\n",
      "        (bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (8): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(200, 200, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "        (bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (9): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(200, 200, kernel_size=(10,), stride=(1,), padding=(5,), bias=False)\n",
      "        (bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (10): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(200, 200, kernel_size=(11,), stride=(1,), padding=(5,), bias=False)\n",
      "        (bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (11): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(200, 200, kernel_size=(12,), stride=(1,), padding=(6,), bias=False)\n",
      "        (bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (12): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(200, 200, kernel_size=(13,), stride=(1,), padding=(6,), bias=False)\n",
      "        (bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (13): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(200, 200, kernel_size=(14,), stride=(1,), padding=(7,), bias=False)\n",
      "        (bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (14): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(200, 200, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
      "        (bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (15): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(200, 200, kernel_size=(16,), stride=(1,), padding=(8,), bias=False)\n",
      "        (bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (max_pool1d): MaxPool1d(kernel_size=2, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (conv1d_projections): ModuleList(\n",
      "      (0): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(3200, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (1): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (pre_highway): Linear(in_features=256, out_features=200, bias=False)\n",
      "    (highways): ModuleList(\n",
      "      (0-3): 4 x Highway(\n",
      "        (H): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (T): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (relu): ReLU()\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (gru): GRU(200, 256, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (post_cbhg_layers): ModuleList(\n",
      "    (0): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
      "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
      "    (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (projections): Linear(in_features=512, out_features=15, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=CBHGModel(\n",
    "            embedding_dim=EMBEDDING_DIM,\n",
    "            inp_vocab_size=VOCAB_SIZE,\n",
    "            targ_vocab_size=LABELS_SIZE,\n",
    "            use_prenet=False,\n",
    "            prenet_sizes=[512, 256],\n",
    "            cbhg_gru_units=256,\n",
    "            cbhg_filters=16,\n",
    "            cbhg_projections=[128, 256],\n",
    "            post_cbhg_layers_units=[256, 256],\n",
    "            post_cbhg_use_batch_norm=True,\n",
    "        )\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:23<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss: 0.0017729900237346767             | Train Accuracy: 0.8619992724038967\n",
      "\n",
      "Saved the best model with accuracy: 0.8619992724038967 to ./models/lstm.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:23<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss: 0.0010672102985831565             | Train Accuracy: 0.9106673673147662\n",
      "\n",
      "Saved the best model with accuracy: 0.9106673673147662 to ./models/lstm.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:23<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss: 0.000809108411910641             | Train Accuracy: 0.9304337281215894\n",
      "\n",
      "Saved the best model with accuracy: 0.9304337281215894 to ./models/lstm.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:23<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss: 0.0006364938873829127             | Train Accuracy: 0.945713246291281\n",
      "\n",
      "Saved the best model with accuracy: 0.945713246291281 to ./models/lstm.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:23<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss: 0.0005277387595749156             | Train Accuracy: 0.955333683657383\n",
      "\n",
      "Saved the best model with accuracy: 0.955333683657383 to ./models/lstm.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:23<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6 | Train Loss: 0.0004359447111973184             | Train Accuracy: 0.9627511217106592\n",
      "\n",
      "Saved the best model with accuracy: 0.9627511217106592 to ./models/lstm.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:24<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7 | Train Loss: 0.0003787111234219671             | Train Accuracy: 0.967197542342051\n",
      "\n",
      "Saved the best model with accuracy: 0.967197542342051 to ./models/lstm.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:25<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 | Train Loss: 0.00032923236926591043             | Train Accuracy: 0.9711184768988237\n",
      "\n",
      "Saved the best model with accuracy: 0.9711184768988237 to ./models/lstm.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:24<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 9 | Train Loss: 0.00029485346811540715             | Train Accuracy: 0.973624641254699\n",
      "\n",
      "Saved the best model with accuracy: 0.973624641254699 to ./models/lstm.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:23<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10 | Train Loss: 0.0002766383837505996             | Train Accuracy: 0.9760095395933546\n",
      "\n",
      "Saved the best model with accuracy: 0.9760095395933546 to ./models/lstm.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train(model, CBHG_PATH, X_train_padded, y_train_padded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
