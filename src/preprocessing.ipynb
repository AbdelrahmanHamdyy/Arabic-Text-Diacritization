{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "OTHER = ' '\n",
    "DIACRITICS = [OTHER, \"َ\", \"ً\", \"ُ\", \"ٌ\", \"ِ\", \"ٍ\", \"ْ\", \"ّ\", \"َّ\", \"ًّ\", \"ُّ\", \"ٌّ\", \"ِّ\", \"ٍّ\"]\n",
    "VOWEL_REGEX = re.compile('|'.join(DIACRITICS))\n",
    "SENTENCE_WINDOW = 800\n",
    "WINDOW_SIZE_BEFORE = 2\n",
    "WINDOW_SIZE_AFTER = 3\n",
    "\n",
    "MAIN_DIACRITICS = None\n",
    "with open(\"./utils/diacritics.pickle\",\"rb\") as file:\n",
    "    MAIN_DIACRITICS = list(pickle.load(file))\n",
    "\n",
    "PUNCTUATIONS = [\".\", \"،\", \":\", \"؛\", \"؟\"]\n",
    "SPLITTING_PATTERN = re.compile(r\"[\\.،:؛!؟]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(path):\n",
    "\tsentences = []\n",
    "\twith open(path, 'r', encoding='utf-8') as file:\n",
    "\t\tfor line in file:\n",
    "\t\t\tsentences.append(line.strip())\n",
    "\n",
    "\treturn sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Getting Basic Arabic Letters based on their unicodes\n",
    "'''\n",
    "basic_arabic_start1 = 0x0621\n",
    "basic_arabic_end1 = 0x063A\n",
    "basic_arabic_start2 = 0x0641\n",
    "basic_arabic_end2 = 0x064A\n",
    "\n",
    "basic_arabic_letters = None\n",
    "with open(\"./utils/arabic_letters.pickle\",\"rb\") as file:\n",
    "    basic_arabic_letters = list(pickle.load(file))\n",
    "\n",
    "VALID_ARABIC_CHARS = basic_arabic_letters + MAIN_DIACRITICS  + PUNCTUATIONS +[' ']\n",
    "VALID_ARABIC_CHARS_WITHOUT_PUNCTUATION = basic_arabic_letters + MAIN_DIACRITICS +[' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_index = {char: i + 1 for i, char in enumerate(basic_arabic_letters)}\n",
    "diacritic_to_index = {diacritic: i for i, diacritic in enumerate(DIACRITICS)}\n",
    "index_to_diacritic = {index: diacritic for diacritic, index in diacritic_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "WHITESPACES_PATTERN = re.compile(\"\\s+\")\n",
    "def combine_whitespaces(text):\n",
    "    return re.sub(WHITESPACES_PATTERN, \" \",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_arabic_letters(text):\n",
    "    text = list(filter(lambda char: char in basic_arabic_letters,text))\n",
    "    return combine_whitespaces(''.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_arabic_text(text):\n",
    "    text = list(filter(lambda char: char in VALID_ARABIC_CHARS,text))\n",
    "    return combine_whitespaces(''.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_arabic_text_without_punctuation(text):\n",
    "    text = list(filter(lambda char: char in VALID_ARABIC_CHARS_WITHOUT_PUNCTUATION,text))\n",
    "    return combine_whitespaces(''.join(text))\n",
    "\n",
    "def separate_words_to_char(sentence):\n",
    "    sentence = get_valid_arabic_text_without_punctuation(sentence)\n",
    "\n",
    "    letters = []\n",
    "    for word in sentence.split():\n",
    "        for char in word:\n",
    "            letters.append(char)\n",
    "\n",
    "    return letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences_window(sentence):\n",
    "    #Fel bdaya ehna 3ayzeen n2smha 600 char 600 char\n",
    "    startIdx = 0\n",
    "    sentences = []\n",
    "    sentence = get_valid_arabic_text_without_punctuation(sentence)\n",
    "    # print(sentence)\n",
    "    while(startIdx < len(sentence) and startIdx != -1):\n",
    "\n",
    "        finalIdx = startIdx + SENTENCE_WINDOW if startIdx + SENTENCE_WINDOW < len(sentence) else -1\n",
    "        \n",
    "        # print(startIdx)\n",
    "        # print(finalIdx)\n",
    "        # print(len(sentence))\n",
    "        if finalIdx != -1 and finalIdx < len(sentence) and sentence[finalIdx] in MAIN_DIACRITICS:\n",
    "            finalIdx -= 1\n",
    "\n",
    "        while(finalIdx != -1 and sentence[finalIdx] != ' '):\n",
    "            finalIdx-=1\n",
    "        #print(\"startIdx: \",startIdx,\"lastIdx: \",finalIdx)\n",
    "        \n",
    "        pre_modified_sentence = sentence[startIdx:finalIdx] if finalIdx != -1 else sentence[startIdx:len(sentence)]\n",
    "\n",
    "        startIdx = finalIdx\n",
    "        \n",
    "        sentences.append(pre_modified_sentence)\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_windows(sentence):\n",
    "    windows =[]\n",
    "    sentence = get_valid_arabic_text_without_punctuation(sentence)\n",
    "    sentence = sentence.split()\n",
    "    for i in range(len(sentence)):\n",
    "        start_idx = max(0,i-WINDOW_SIZE_BEFORE)\n",
    "        last_index = min(len(sentence),i+WINDOW_SIZE_AFTER+1)\n",
    "        windows.append(sentence[start_idx:last_index])\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_splitted_sentences(sentence):\n",
    "    sentence = get_valid_arabic_text(sentence)\n",
    "    #return [item.strip() for item in re.split(SPLITTING_PATTERN, sentence)]\n",
    "    windows = get_sentences_window(sentence)\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_words_and_diacritics(sentence):\n",
    "    sentences = get_splitted_sentences(sentence)\n",
    "    final_chars = []\n",
    "    final_diacritics = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        output_chars = []\n",
    "        output_diacritics = []\n",
    "        for word in sentence.split():\n",
    "            letters = []\n",
    "            diacritics = []\n",
    "            prev_char = word[0]\n",
    "            if len(word) == 1:\n",
    "                letters.append(prev_char)\n",
    "                diacritics.append(OTHER)\n",
    "            else:\n",
    "                for idx, char in enumerate(word[1:]):\n",
    "                    try:\n",
    "                        next_char = word[idx + 1 + 1]\n",
    "                    except IndexError:\n",
    "                        next_char = ''\n",
    "                    if char in DIACRITICS:\n",
    "                        if prev_char not in DIACRITICS:\n",
    "                            letters.append(prev_char)\n",
    "                            if next_char == '' or next_char not in DIACRITICS:\n",
    "                                diacritics.append(char)\n",
    "                            elif next_char in DIACRITICS:\n",
    "                                # print(char+next_char)\n",
    "                                diacritics.append(char + next_char)\n",
    "                    else:\n",
    "                        if prev_char not in DIACRITICS:\n",
    "                            letters.append(prev_char)\n",
    "                            diacritics.append(OTHER)\n",
    "                        if next_char == '':\n",
    "                            letters.append(char)\n",
    "                            diacritics.append(OTHER)\n",
    "                    prev_char = char\n",
    "\n",
    "            if len(letters):\n",
    "                output_chars.append(letters)\n",
    "                output_diacritics.append(diacritics)\n",
    "\n",
    "        final_chars.append([char for word in output_chars for char in word])\n",
    "        final_diacritics.append([diacritic for word in output_diacritics for diacritic in word])\n",
    "\n",
    "    final_chars = [item for item in final_chars if len(item)]\n",
    "    final_diacritics = [item for item in final_diacritics if len(item)]\n",
    "    return final_chars, final_diacritics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_sizes():\n",
    "    training_letters = 0\n",
    "    preprocessed_letters = 0\n",
    "\n",
    "    TEST_PATH = \"../dataset/train.txt\"\n",
    "\n",
    "    #calculating training letters\n",
    "\n",
    "    test_corpus = readFile(TEST_PATH)\n",
    "\n",
    "    X_test = []\n",
    "    total_len = 0\n",
    "    cnt = 0\n",
    "\n",
    "    # print(test_corpus[10])\n",
    "    # print(get_splitted_sentences(test_corpus[10]))\n",
    "\n",
    "    # START = 3 END = 4 IS BUGGY\n",
    "\n",
    "    START = 1612\n",
    "    END = 1613\n",
    "\n",
    "    looping_cnt = 0\n",
    "    for j, sentence in enumerate(test_corpus):\n",
    "        char_list, _ = separate_words_and_diacritics(sentence.strip())\n",
    "        char_list_second = get_valid_arabic_letters(sentence.strip())\n",
    "        for i in range(len(char_list)):\n",
    "            for char_wanted in char_list[i]:\n",
    "                # print(\"ely ana bgebu:\" ,char_wanted, \"->\", \"ely hwa bygebu :\",char_list_second[looping_cnt])\n",
    "                # print(\"-------------------\")\n",
    "                looping_cnt+=1\n",
    "            cnt+=len(char_list[i])\n",
    "\n",
    "\n",
    "    real_cnt = 0\n",
    "    for sentence in test_corpus:\n",
    "        # print(sentence)\n",
    "        char_list = get_valid_arabic_letters(sentence.strip())\n",
    "        real_cnt+=len(char_list)\n",
    "\n",
    "    print(real_cnt)\n",
    "    print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8351478\n",
      "8351478\n"
     ]
    }
   ],
   "source": [
    "# check_data_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
